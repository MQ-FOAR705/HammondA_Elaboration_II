%--Packages
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{titling}
\usepackage{fancyhdr} %--for fancy header/ footers
\usepackage{tikz} %--for border in title page
\usetikzlibrary{calc} %-- access to tikslibrary commands
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{verbatimbox}


%--Parameters
\title{Elaboration Document II}
\author{Aaron Hammond\\43691455}
\date{August 2019}
\fancyhfoffset
\fancy
\definecolor{collink}{RGB}{45, 95, 140}
\setcounter{tocdepth}{1}
\hypersetup{
colorlinks,
linkcolor=collink,
linktoc=all
}

%--Page Setup
\pagestyle{fancy}
\fancyhf{}

\rhead{Elaboration Exercise II}
\lhead{Digital Humanities}

\fancyfoot[RE,RO]{Aaron Hammond | 43691455}
\fancyfoot[LE,LO]{Page: \thepage}

\renewcommand{\headrulewidth}{2pt}
\renewcommand{\footrulewidth}{1pt}
%--Commands

\newcommand\HRule{\rule{\textwidth}{1pt}} %-- horizontal lines for formatting

\newcommand{\intention}[1]{\noindent \textbf{Intention:}{\textnormal\ #1} \newline}
\newcommand{\action}[1]{\textbf{Action:}{\textnormal\ #1} \newline}
\newcommand{\result}[1]{\textbf{Result:}{\textnormal\ #1} \newline}
\newcommand{\solution}[1]{\textbf{Solution:}{\textnormal\ #1} \newline}

%--
\begin{document}

%--Title page

\begin{titlepage}

\begin{tikzpicture}[remember picture, overlay]
  \draw[line width = 4pt] ($(current page.north west) + (1in,-1in)$) rectangle ($(current page.south east) + (-1in,1in)$);
\end{tikzpicture}

\begin{center}
\HRule\\[0.4cm]
\huge{Elaboration Document II}\\[0.5cm]
\huge{Aaron Hammond}\\
\large{\today}\\[0.4cm]

\HRule \\[1cm]
\end{center}

\begin{justify}
\noindent This document is the second stage of of the elaboration process. It contains the steps and processes I fulfilled in order to achieve the project scope outlined in the first elaboration document. This document maintains the same structure as the previous, the steps are as follows:
\end{justify}


\def\contentsname{\empty} %--Remove contents header from toc
\tableofcontents

\end{titlepage}

%--

\section{Transcribe audio into plain text}
In this step i attempted to use the range of audio transcribers. While in future i will test Alveo's service. For the sake of this elaboration i manually transcribed using oTranscriber. Manually transcribing wasn't as laborious as I had anticipated and depending on the success I have with Alveo, it's good to know that oTranscriber will be a viable backup plan.

\subsection{FTW Transcriber}
\intention{Download and use FTW Transcriber to automatically transcribe audio files.}
\action{I went to the website to download and read that this software will not automatically transcribe but is a tool to assist manually transcribing}
\result{I downloaded it and kept it as a backup option}

\subsection{Alveo Audio Transcriber}

\intention{Utilise the online service of Alveo for transcription.}
\action{As this software coordinates with universities i logged in using my credentials in order to access the service}
\result{Before i can use the service, my application must be approved. I cannot try this software, so I will look for another solution}

\subsection{oTranscribe}

\intention{Use the online service oTranscriber to automatically transcribe audio files.}
\action{I discovered that this software was a tool to assist manual transcribing and not automatically as i previous thought}
\result{In order to progress with the elaboration exercise i manually transcribed a short audio file using oTranscribe}

\intention{Manually transcribe}
\action{My test file type was .aac and in order to be able to use the service i needed to convert it (so i did using \url{https://www.media.io/})}
\result{The process was actually quite easy. However it takes time and attention. The keyboard commands are easy and intuitive and the features such as speed and playback control are adequate. Lastly, export formats are varied and i exported to .txt}



\section{Convert articles into simple text}
This step of the project proved the most difficult due to the protections in place to prevent PDF files from being converted. While I was successful in converting one into a .doc file and copying that information into a txt file, I feel that a more simpler solution can be achieved. Perhaps a change in scope to only focus on the abstract instead of the whole document.
\subsection{UniPDF}
\intention{Convert a PDF into a .txt file}
\action{Loaded UniPDF and imported PDF "Citizenship collective identity" and converted it}
\result{The conversion was successful but in the text file itself there was only the meta data stored, no words from the article or abstract itself}

\intention{Convert a PDF into a .txt file (#2)}
\action{Loaded UniPDF and imported PDF "Russification in the baltic states" and converted it to .txt}
\result{Again the conversion was successful but the contents were lacking anything more than the metadata}

\intention{Convert a PDF into a .doc file}
\action{Loaded UniPDF and imported PDF "Russification in the baltic states" and converted it to .doc}
\result{Conversion was successful and created a 98mb doc file. The file had readable contents. I copied the contents into a .txt file and saved it successfully}

\subsection{Zamzar}
As a result of the multiple step case with UniPDF I decided to try my other option.\\
\intention{Convert a PDF to .txt using Zamzar}
\action{Uploaded the "Russification in the baltic states" pdf file}
\result{The document could not be converted due to DRM software that prevents it. For the elaboration process will continue with the results from UniPDF}


\section{Create plain text files from field notes}
For the purposes of this project. Joplin's export format will work for this step in the process. The export file will be a jex file which can be simply changed to txt using a batch file without issue or worry. 

\subsection{Joplin}
\intention{Export notes from Joplin into a simple text format}
\action{Right-click the note or library for export and selected .jex file}
\result{The file created is simple text and editable with notepad. Only addition is it includes a header that must work with Joplin in order to import correctly. Changed file to a .txt file and is still read-able}

\section{Folder and file naming structure}
\subsection{Folder Structure (in Windows)}
\intention{Create three subfolders in my project folder}
\action{(Right-cick, new, folder) three times with various names}
\result{Folder structure successfully configured, sibling folders of interviews, articles and fieldnotes}

\intention{Write and run a batch file to add a prefix to each file}
\action{Created and wrote batch file in the parent folder}
\result{Command line window blinked and disappeared, no files were changed}

\intention{Write and run a batch file to add prefix to each file (#2)}
\action{Added an initial cd command to locate the folder where it is being run from}
\result{Same result as before, nothing was renamed}

\intention{Write and run a batch file to add prefix to each file (#3)}
\action{Used a different command of ren}
\result{Renamed the file with the intended prefix for one specific folder}

\intention{Write and run a batch file to add prefix to each file (#4)}
\action{Added additional navigation and renaming commands}
\result{All files were renamed with the desired prefix}




\section{Analyze text files}
Analyzing the files turned out to be the most fruitful step in the process. The two tools I used below both worked remarkably. The only adjustment that I would like to make however is to add to my batch file so that all renamed files are moved to a singular folder for analysis to allow easier use of the Voyant Tool.

\subsection{AntConc}
\intention{Use AntConc to select all my sources and identify patterns}
\action{Loaded up the program and selected my parent directory of my sources}
\result{I need to enter the word, theme or pattern i want to draw out from my sources. Still very good software, and identifying what i want to search for may be better. The software successfully identified what areas of each file contained my search term and identified where it could be found}

\subsection{Voyant Tools}

\intention{Use Voyant Tools to collectively analyze my collection of sources}
\action{I moved all the files into a single directory and selected them all together in order to use the service}
\result{The analysis provided was equipped with wordclouds, graphs and various means to identify themes throughout the sources.}
\
\newpage
\section*{Conclusion}
In total the plan appears sound. By using the process outline in my scoping document I was able to use various types of software and data exchange to convert all my data into a single-workable format. Organise those files within the specified folder structure. Add a prefix to each source type for quick and efficient identification within various interfaces. 

\end{document}
